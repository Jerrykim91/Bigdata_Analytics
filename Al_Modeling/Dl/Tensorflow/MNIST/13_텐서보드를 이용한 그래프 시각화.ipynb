{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"13_텐서보드를 이용한 그래프 시각화.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyNvc7wKu6Gi/qJoIUWPiNcX"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"G81wsopMWH9U","colab_type":"code","colab":{}},"source":["# 텐서보드 \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQ4ZhP9HWZSt","colab_type":"code","colab":{}},"source":["# 텐서 보드 모듈 가지고 오기 \n","from tensorboardcolab import *\n","import shutil, os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oho02Cf8WZQV","colab_type":"code","colab":{}},"source":["try : \n","    path = './Graph' \n","    shutil.rmtree(path, ignore_errors = True)\n","    os.mkdir(path)\n","    print('정상')\n","except Exception as err : \n","    print('에러 발생', err)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lagf91PjWZNr","colab_type":"code","colab":{}},"source":["tbc = TensorBoardColab()\n","# 서버 로딩을 확인 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1XRgF7m_WZLJ","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.examples.tutorials.mnist import input_data\n","\n","mnist = input_data.read_data_sets('./data/mnist/', one_hot=True)\n","\n","pixels = mnist.train.images.shape[1]  # 이미지 한개당 특징(feature)의 크기 \n","nums = mnist.train.labels.shape[1]    # 레이블 특징(feature)의 크기\n","pixel_wh = int( np.sqrt( pixels ) )   # 이미지 1개당 가로 혹은 세로 크기\n","\n","x = tf.placeholder(tf.float32 , shape =(None, pixels), name = 'x' ) # 플레이스 홀더\n","\n","# 가중치 필터 W를 만드는 함수 \n","def makeWeightVariable(shape, name):\n","    init_d = tf.truncated_normal(shape, stddev= 0.1) # 초기값\n","    W      = tf.Variable(init_d, name = 'W_'+name) # W를 생성\n","    return W   # 가중치 필터(커널) W를 리턴\n","\n","# 편향을 만드는 함수 \n","def makeBiasVariable(shape, name):\n","\n","    init_b = tf.constant( 0.1, shape=[shape] ) \n","    b      = tf.Variable( init_b, name='b_' + name )\n","    return b   # 편향 값을 리턴 받는다.\n","\n","# 합성곱층을 만드는 함수 \n","def makeConv2d(x, W, name):\n","    conv2d = tf.nn.conv2d(x, W, strides=[1,1,1,1], padding= \"SAME\", name = 'conv_'+name )\n","    return conv2d\n","\n","# 풀링함수 -> 최대풀링 \n","def makeMaxPooling( x ):\n","    return tf.nn.max_pool( x, ksize = [1, 2, 2, 1], strides = [1 ,2, 2, 1], padding = 'SAME'  )\n","\n","# 합성곱층 1 생성, 입력대비 출력까지의 모든 관계(그래프)를 표현 \n","with tf.name_scope('conv1') as scope:\n","    W = makeWeightVariable( [5, 5, 1, 32 ] , 'conv1' )\n","    b = makeBiasVariable(32 , 'conv1')  # b\n","    # x : 입력층 (None, 784) => (batch(배치), h(세로), w(가로), channel(채널))\n","    x_imgs  = tf.reshape(x, (-1, pixel_wh, pixel_wh, 1))\n","    h_conv1 = tf.nn.relu( makeConv2d( x_imgs, W,'conv1') + b )  # conv1\n","\n","# 풀링층 1 생성 \n","with tf.name_scope('pool1') as scope:\n","    h_pool1 = makeMaxPooling( h_conv1 )\n","\n","# 합성곱층 2  생성 \n","name_conv2 = 'conv2'\n","with tf.name_scope(name_conv2) as scope:\n","    # [5(h), 5(w), 32(입력채널수=이전단계의출력채널수), 64(최종 출력채널수)]\n","    W_conv2 = makeWeightVariable( [5, 5, 32, 64 ], name_conv2 )\n","    b_conv2 = makeBiasVariable( 64, name_conv2 )\n","    h_conv2 = tf.nn.relu( makeConv2d( h_pool1, W_conv2, name_conv2 ) + b_conv2 )\n","\n","# 풀링층 2\n","with tf.name_scope('pool2') as scope:\n","    h_pool2 = makeMaxPooling( h_conv2 )\n","\n","# 전 결합층 \n","with tf.name_scope('fully_conected') as scope:\n","    num = 7 * 7 * 64 \n","    W_flat = makeWeightVariable([num, 1024],'fully_conected')\n","    h_pool2_flat = tf.reshape(h_pool2,[-1, num])\n","    h_fc = tf.nn.relu(tf.matmul(h_pool2_flat, W_flat ))\n","\n","# 드롭아웃층 \n","with tf.name_scope('dropout') as scope:\n","    keep_prob = tf.placeholder(tf.float32)\n","    h_fc_drop = tf.nn.dropout(h_fc, rate=1-keep_prob)\n","\n","# 출력 층 \n","with tf.name_scope('output') as scope:\n","    # nums = 10\n","    W_output = makeWeightVariable( [1024,nums], 'output' )   # W\n","    b_output = makeBiasVariable( nums, 'output' )         # b\n","\n","    # y_conv => tf.nn.softmax( tf.matmul(x,w)+b)\n","    # x => h_fc_drop\n","    y_conv = tf.nn.softmax( tf.matmul(h_fc_drop,W_output)+b_output)\n","\n","\n","y_ = tf.placeholder(tf.float32, shape=(None, nums), name = 'y_') # 정답\n","\n","\n","# 크로스 엔트로피 \n","with tf.name_scope('loss') as scope:\n","    cross_entropy = - tf.reduce_sum(y_ * tf.log(y_conv))\n","\n","# 경사하강법 \n","with tf.name_scope('agd') as scope:\n","    optimizer = tf.train.AdamOptimizer()\n","    train = optimizer.minimize( cross_entropy )\n","\n","# 예측, 평가 관련 플로우작성 \n","with tf.name_scope('predict') as scope:\n","    predict = tf.equal(tf.arg_max(y_conv, 1 ),tf.arg_max(y_, 1 ))  # 예측\n","    accuracy = tf.reduce_mean(tf.cast(predict, tf.float32)) # 정확도 \n","\n","# 주입할 데이터의 모양을 세팅해주는 함수를 구성 \n","def makeFeedDictParam(imgDatas, labels, prob):\n","    return { x: imgDatas , y_: labels , keep_prob:prob } \n","\n","# 실전\n","TRAIN_COUNTS = 3000      # 설정값\n","ONE_TRAIN_COUNTS = 50    # 한번 훈련시 사용하는 데이터의 양 \n","VERBOSE_TERM = 100       # 100번째 훈련이 되면 로그를 출력 \n","\n","with tf.Session() as sess: \n","    init = tf.global_variables_initializer()\n","    sess.run(init)  # 초기화 \n","    test_img = mnist.test.images\n","    test_lab = mnist.test.labels\n","    keep_prob_size  = 1\n","    test_feedDict = makeFeedDictParam( test_img, test_lab, keep_prob_size)\n","\n","    for step in range(TRAIN_COUNTS):   # 0~2999 : 3천번 수행 \n","        batch = mnist.train.next_batch(ONE_TRAIN_COUNTS)  #  0:이미지 데이터, 1:레이블정답 데이터\n","        train_fdp = makeFeedDictParam( batch[0],  batch[1], 0.5)\n","        _, loss =sess.run([train, cross_entropy],feed_dict= train_fdp )\n","\n","        if step % VERBOSE_TERM == 0 :\n","            acc = sess.run( accuracy, feed_dict = test_feedDict )\n","            print('s=%4s, a=%20s, l=%20s' % (step, acc, loss) ) \n","\n","    acc = sess.run( accuracy, feed_dict = test_feedDict )\n","    print('-'*50)\n","    print('최종 결과')\n","    print( 's=%4s, a=%20s, l=%20s' % (step, acc, loss) )\n","    print('-'*50)\n","\n","  # Session이 살아 있는 공간에서 텐서보드용 데이터를 저장\n","  # 모든 훈련이 끝난후 \n","    writer = tbc.get_writer()\n","    writer.add_graph( sess.graph )\n","    # 버퍼에 저장된 내용을 파일에 강제로 밀어낸다. \n","    writer.flush()\n","\n","# 텐서보드 코랩 닫기 \n","tbc.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yEg3sWe7WZIx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AztUiq_oWZGD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tm0AwKslWZDb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xXhHeHPLWZAu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lHCgSaHPWY-d","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EHKkCADhWY73","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bXIw4KuLWY5A","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FeElQB7jWY2t","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HmJyNKcFWY0V","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}