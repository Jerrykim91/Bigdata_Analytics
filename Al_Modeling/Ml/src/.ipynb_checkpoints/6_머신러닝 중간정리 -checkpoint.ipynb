{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개요 \n",
    "---\n",
    "- 머신러닝 \n",
    "- 데이터 => 정보 => 지식 =>지혜\n",
    "- 데이터로부터 지식/지혜(통찰등등)를 추출하는 작업\n",
    "- 통계학, 컴퓨터 사이언스, 데이터 마이닝, 인공지능등이 다 섞여 있음\n",
    "- 예측 분석, 통계적 머신러닝 등등 칭하는 명칭도 다양 \n",
    "\n",
    "\n",
    "\n",
    "# 정의\n",
    "___\n",
    "\n",
    "- 명시적 프로그래밍 단계가 없이 컴퓨터가 스스로 학습하게 하는 능력을 갖추게 하는 연구 분야  \n",
    "\n",
    "- 예 ) 스팸 필터 \n",
    "  - T : Task, 새로운 메일이 스펨인지 아닌지를 구분\n",
    "  - E : Experience, 훈련데이터 (시스템이 학습하는 샘플)\n",
    "  - P : Perperence, 정확하게 스펨 메일을 걸러내는 비율 -> 정확도\n",
    "  - 이 프로그램은 작업 T와 성능 측정 P에 대한 경험 E로 학습한것이다\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "  \n",
    "# 머신러닝 시스템의 종류 \n",
    "---\n",
    "\n",
    "- 학습하는 동안의 감독형태, 정보량, 정보의 형태등에 따라 나눠진다\n",
    "\n",
    "    - 지도 학습 : superised learning\n",
    "        - 분류 \n",
    "            - 스팸 필터(스팸의 여부)\n",
    "        - 회귀 \n",
    "            - 중고차 가격을 예측(특성: 주행거리, 연식, 브랜드, 사고이력)이를 통한 수치 예측 \n",
    "        - 알고리즘 \n",
    "            - K-최근접 이웃, 선형회귀, 로지스틱회귀, 서포트백터머신, 결정트리, 랜텀포레스트, XG부스트, 신경망 \n",
    "          \n",
    "    - 비지도 학습: unsuperised learning\n",
    "    \n",
    "        - 훈련데이터에 레이블이 없다.\n",
    "        \n",
    "        - 예시\n",
    "            - 블로그/ 사이트 방문자 그룹화\n",
    "            \n",
    "                - 알고리즘 스스로가 방문자 사이의 연결고리를 찾는다\n",
    "                    - 예) 방문자의 50% 기혼자, 이들은 영화 장르를 선호한다\n",
    "                    - 예) 전체 방문자의 80% 21~22사이에 많이들어온다 등등 \n",
    "                    - 예) 국가 별 방문 기록, 등등 \n",
    "                        - 군집화 - 유형을 찾아내고 생성\n",
    "                        \n",
    "            - 시각화 \n",
    "               - 고차원 데이터를 삽입하여 도식화 \n",
    "               - 2d/3d등으로 표현 \n",
    "                   - 알고리즘은 구조를 유지하려고 하는 경향을 가진다. \n",
    "               - 패턴을 추출 \n",
    "                \n",
    "            - 차원 축소\n",
    "               - 정보의 손실을 최소화 \n",
    "                   - 데이터를 간소화\n",
    "                    \n",
    "               - 여러 특성을 하나의 특성으로 합치는 과정 \n",
    "                   - 아이리스의 특성이 4 -> 2개로 줄인다.\n",
    "                   - 특성이 많으면 적용할만한 상황으로 판단한다.   \n",
    "                    \n",
    "               - 주행거리, 연식 관련데이터를 차원 축소를 통해서 마모도라는 특성으로 합친다.     \n",
    "               - 차원 축소\n",
    "                   - 실행/ 학습 속도 상승 \n",
    "                       - 디스크 메모리상 연산상 점유율을 줄이고 \n",
    "                           - 생산성이 향상, 정화도고 상승될 수 있다.    \n",
    "\n",
    "                - 이상치 탐지 \n",
    "                     - 부정 거래 탐지 \n",
    "                     - 부정 대출 탐지 \n",
    "                     - 제조 결함 감지( 품질관리, 금융, IOT-> 시계열 -> RNN+LSTM)\n",
    "                     - 학습 데이터에서 이상치 제거    \n",
    "                         \n",
    "                - 연관 규칙학습 \n",
    "                    - 대량의 데이터에서 특성간의 흥미로운 관계를 찾아내는 것 \n",
    "                    - 편의점 / 마트 / 슈퍼마켓 / 온라인 상점 \n",
    "                        - POS( VAN사(VISA, BC,PG사(이니시스,LLG, 서브PG사, POS회사(한국정보통신) ) \n",
    "                        - 물품들 간의 연관규칙을 찾을수 있다 \n",
    "                        - 오프라인 매장이면 매데 배치, 온라인 마케팅등등 적용)           \n",
    "    - 준지도 학습: semi-superised earning\n",
    "    \n",
    "        - 레이블이 일부만 존재 \n",
    "        - 레이블이 있는 데이터는 소수\n",
    "        - 지도학습 + 비지도 학습 연계\n",
    "            - 여러 모형을 섞어서 구현 \n",
    "             \n",
    "    - 강화 학습: Reinforcement Learning\n",
    "    \n",
    "        - 딥러닝때 자세히 \n",
    "        - 에이전트 : 학습을 수행하는 시스템 \n",
    "        - 리워드(긍적적 보상), 패널티(부정적보상)\n",
    "        - 예 : 딥마인드의 알파고 \n",
    "        \n",
    "            - 알파 제로      \n",
    "                - 이미 성린된 그간의 전략을 이용\n",
    "                - 학습은 오프라인방식(대국 중에는 따로 학습하지 않았다) \n",
    "                - 커제 압승\n",
    "                \n",
    "            - 수백/수천만/수억덩의 게임을 분석      \n",
    "                - 승리에 대한 전략 학습 \n",
    "                - 대국중에도 계속해서 알고리즘을 발전시키면서 대전 \n",
    "                    - 이세돌 이벤트시, 알파고\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습법\n",
    "---\n",
    "\n",
    "- 입력 데이터의 스트림(데이터의 연속적인 흐름)으로 부터 점진적 학습의 가능 여부 \n",
    " \n",
    "## 오프라인 학습(배치 학습)\n",
    "---\n",
    "\n",
    "- 새로운 학습 데이터를 학습에 적용하기 위해서 \n",
    "    - 전체 데이터(이전 데이터 + 신규 데이터)를 사용하여 새로운 버전으로 다시 학습/ 훈련 \n",
    "    - 적용방법 \n",
    "        - 시스템 중단, 새로운 알고리즘으로 교체 , 시스템가동 => REATSET(재가동)\n",
    "\n",
    "   - 주기 \n",
    "        - 24시간, 매주 , 매월 \n",
    "            - 사전에 교체에 대한 연습 / 시뮬레이션 \n",
    "                - 자동화 고민 \n",
    "\n",
    "    - 고려사항 \n",
    "        - 시간이 많이 지나면 \n",
    "            - 데이터가 쌓여간다\n",
    "                - 학습 비용이 상승한다(돈 /시간)\n",
    "                - 언젠가는 불가능하게 된다 \n",
    "                    - 어느정도 데이터가 많아지면 (사이트 별로 다르지만)\n",
    "                    - 온라인 학습으로 넘어가야한다\n",
    "\n",
    "        - 자원이 제한된 시스템인경우\n",
    "            - 스마트폰 , 화성탐사로봇\n",
    "            - 학습에 모든 리소스를 할당할수 없다. 자원의 분배가 필요\n",
    "\n",
    "        - 시스템훈련비용\n",
    "        - 제품에 적용하는 방식\n",
    "        - 서비스 초기, 어느정도 데이터가 구출 될때까지 OK \n",
    "        - 롤백기능도 준비(v1.0.1 -> v1.0.0 되돌릴수 있는가?)   \n",
    "\n",
    "                    \n",
    "                    \n",
    "## 온라인 학습 ( 세미배치학습, 점진적 학습법 - incremental learning ) \n",
    "---\n",
    "\n",
    "- 데이터를 순차적으로 미니 batch(데이터량) 단위로 기존 알고리즘에 주입하여 시스템(알고리즘)을 훈련시킨다      \n",
    "\n",
    "- 매단계 빠르고, 비용도 적게 든다    \n",
    "\n",
    "- 데이터가 도착하는 대로(한개 ~ n개) 즉시 적용      \n",
    "    - 게임, 주식, 자율주행 등등 빠른 변화에 대응하는 시스템에 적합\n",
    "\n",
    "- 자원이 한정적이다      \n",
    "    - 학습이 끝나면 데이터(로그처리)는 버린다\n",
    "        - 롤백 가능하게 구성, 완전 삭제까지는 7일후?\n",
    "\n",
    "- 데이터는 외부 디스크상에서 읽고 => 주입 => 로드 => 학습 => 버린다       \n",
    "\n",
    "- 단점 : 나쁜 데이터가 주입되면 => 시스템 성능이 저하된다!!   \n",
    "    - 이상탐지, 성능평가등 데이터의 대한 평가가 수행되고 나서 주입\n",
    "    - 롤백기능이 강화\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 방식 \n",
    "--- \n",
    "\n",
    "- 목표 : 새로운 샘플(한번도 접하지 못한 데이터)이 잘 작동하게 하는 모델을 구축\n",
    "\n",
    "- 사례 기반 학습\n",
    "    - 목표를 단순하게 기억하는 방식\n",
    "    - 스펨 메일-> 스펨으로 분류되는 모든 메일을 기억한다 -> 동일 유형 분류해 낸다\n",
    "    - 사례를 많이 기억하여 학습을 수행\n",
    "    \n",
    "- 모델 기반 학습\n",
    "    - 전체데이터의 샘플로 모델을 만들어서 예측을 사용\n",
    "    - 1인당 GDP가 증가할수록 삶의 질/만족도는 좋아지는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
